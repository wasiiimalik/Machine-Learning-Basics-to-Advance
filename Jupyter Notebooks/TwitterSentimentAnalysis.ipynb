{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import The Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLoading train and test data\u001b[0m\n",
      "\u001b[33mData loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(colored(\"Loading train and test data\", \"yellow\"))\n",
    "train_data = pd.read_csv('clean_train.csv') #FOR MODEL TRAINING\n",
    "test_data = pd.read_csv('clean_test.csv') #FOR MODEL TESTING\n",
    "print(colored(\"Data loaded\", \"yellow\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SweetCandiesXXX if u came to visit here in 17...</td>\n",
       "      <td>0</td>\n",
       "      <td>came visit choic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanks @Just4Julia! good advice for this day  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>thank good advic day quotsmil fear sorrow smil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@RogJ  Thank you, Roger! Oh, and very nice to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>thank roger Oh nice see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@MattMazur Hi Matt, how are you today? I am im...</td>\n",
       "      <td>4</td>\n",
       "      <td>Hi matt today improv french tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@MrsNickJonass that's cool, i like it</td>\n",
       "      <td>4</td>\n",
       "      <td>that' cool like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment  \\\n",
       "0  @SweetCandiesXXX if u came to visit here in 17...          0   \n",
       "1  thanks @Just4Julia! good advice for this day  ...          4   \n",
       "2  @RogJ  Thank you, Roger! Oh, and very nice to ...          4   \n",
       "3  @MattMazur Hi Matt, how are you today? I am im...          4   \n",
       "4             @MrsNickJonass that's cool, i like it           4   \n",
       "\n",
       "                                         Clean_tweet  \n",
       "0                                   came visit choic  \n",
       "1  thank good advic day quotsmil fear sorrow smil...  \n",
       "2                            thank roger Oh nice see  \n",
       "3                  Hi matt today improv french tweet  \n",
       "4                                    that' cool like  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nicholasmw 1 day u will find that girl worry</td>\n",
       "      <td>4</td>\n",
       "      <td>day find girl worri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there is nothing on tv and im so desperate to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>noth tv im desper entertain im watch hihow sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very excited that greys is on tonight. Not so ...</td>\n",
       "      <td>0</td>\n",
       "      <td>veri excit grey tonight not happi season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2pm's again and again is a great song. Nichkhu...</td>\n",
       "      <td>4</td>\n",
       "      <td>pm' great song nichkhun hwait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My teeth hurt</td>\n",
       "      <td>0</td>\n",
       "      <td>My teeth hurt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment  \\\n",
       "0     @nicholasmw 1 day u will find that girl worry           4   \n",
       "1  there is nothing on tv and im so desperate to ...          0   \n",
       "2  Very excited that greys is on tonight. Not so ...          0   \n",
       "3  2pm's again and again is a great song. Nichkhu...          4   \n",
       "4                                     My teeth hurt           0   \n",
       "\n",
       "                                      Clean_tweet  \n",
       "0                             day find girl worri  \n",
       "1  noth tv im desper entertain im watch hihow sad  \n",
       "2        veri excit grey tonight not happi season  \n",
       "3                   pm' great song nichkhun hwait  \n",
       "4                                   My teeth hurt  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert The tweet Into Sequence of number array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTokenizing and padding data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(colored(\"Tokenizing and padding data\", \"yellow\"))\n",
    "tokenizer = Tokenizer(num_words = 2000, split = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_data['Clean_tweet'].astype(str).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           came visit choic\n",
       "1          thank good advic day quotsmil fear sorrow smil...\n",
       "2                                    thank roger Oh nice see\n",
       "3                          Hi matt today improv french tweet\n",
       "4                                            that' cool like\n",
       "                                 ...                        \n",
       "1279995    alreadi saw mtv movi award adv global tvbut te...\n",
       "1279996                         So appar wait fuel truck min\n",
       "1279997    happi bank holiday weekend saturday open shop ...\n",
       "1279998                                             i'm cold\n",
       "1279999    just dropp sister train station she' go back u...\n",
       "Name: Clean_tweet, Length: 1280000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Clean_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[352, 449, 1017],\n",
       " [13, 6, 1581, 5, 1703, 482, 167, 45],\n",
       " [13, 38, 71, 20],\n",
       " [219, 1501, 10, 1847, 867, 84],\n",
       " [82, 139, 8]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets = tokenizer.texts_to_sequences(train_data['Clean_tweet'].astype(str).values)\n",
    "train_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(i) for i in train_tweets])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,  352,  449, 1017],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   13,\n",
       "           6, 1581,    5, 1703,  482,  167,   45],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,   13,   38,   71,   20],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,  219, 1501,   10, 1847,  867,   84],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,   82,  139,    8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets = pad_sequences(train_tweets, maxlen = max_len)\n",
    "train_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTokenizing and padding complete\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_tweets = tokenizer.texts_to_sequences(test_data['Clean_tweet'].astype(str).values)\n",
    "test_tweets = pad_sequences(test_tweets, maxlen = max_len)\n",
    "print(colored(\"Tokenizing and padding complete\", \"yellow\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    5,  120,  128,  386],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  197,\n",
       "         346,   23, 1729, 1308,   23,   28,   51],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         544,  166, 1776,   67,    1,   58,  450],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,   46,  157],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,   44, 1066,  144]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The LSTM model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCreating the LSTM model\u001b[0m\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 128)           256000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 40, 128)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               394240    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 650,754\n",
      "Trainable params: 650,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "print(colored(\"Creating the LSTM model\", \"yellow\"))\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, 128, input_length = train_tweets.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(256, dropout = 0.2))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The LSTM MODEL on 10 Epocs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  s  t\n",
      "0  0  1  0\n",
      "1  1  0  0\n",
      "2  0  0  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "li = ['s', 'a', 't']\n",
    "print(pd.get_dummies(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  4\n",
       "0        1  0\n",
       "1        0  1\n",
       "2        0  1\n",
       "3        0  1\n",
       "4        0  1\n",
       "...     .. ..\n",
       "1279995  1  0\n",
       "1279996  1  0\n",
       "1279997  0  1\n",
       "1279998  1  0\n",
       "1279999  0  1\n",
       "\n",
       "[1280000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(train_data['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTraining the LSTM model\u001b[0m\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 747s 93ms/step - loss: 0.4807 - accuracy: 0.7672 - val_loss: 0.4665 - val_accuracy: 0.7760\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 833s 104ms/step - loss: 0.4623 - accuracy: 0.7786 - val_loss: 0.4566 - val_accuracy: 0.7815\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 823s 103ms/step - loss: 0.4555 - accuracy: 0.7825 - val_loss: 0.4534 - val_accuracy: 0.7839\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 869s 109ms/step - loss: 0.4511 - accuracy: 0.7851 - val_loss: 0.4515 - val_accuracy: 0.7851\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 872s 109ms/step - loss: 0.4468 - accuracy: 0.7878 - val_loss: 0.4495 - val_accuracy: 0.7867\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 904s 113ms/step - loss: 0.4432 - accuracy: 0.7897 - val_loss: 0.4497 - val_accuracy: 0.7861\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 889s 111ms/step - loss: 0.4400 - accuracy: 0.7913 - val_loss: 0.4484 - val_accuracy: 0.7868\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 863s 108ms/step - loss: 0.4368 - accuracy: 0.7932 - val_loss: 0.4518 - val_accuracy: 0.7873\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 754s 94ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4482 - val_accuracy: 0.7863\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 804s 100ms/step - loss: 0.4323 - accuracy: 0.7958 - val_loss: 0.4516 - val_accuracy: 0.7872\n",
      "\u001b[32m<keras.callbacks.History object at 0x0000024C807BACD0>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "print(colored(\"Training the LSTM model\", \"green\"))\n",
    "history = model.fit(train_tweets, pd.get_dummies(train_data['Sentiment']).values, epochs = 10, batch_size = 128, validation_split = 0.2)\n",
    "print(colored(history, \"green\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating how accurate is our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTesting the LSTM model\u001b[0m\n",
      "2500/2500 [==============================] - 83s 33ms/step - loss: 0.4511 - accuracy: 0.7880\n",
      "Test accuracy: 0.787987470626831\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "print(colored(\"Testing the LSTM model\", \"green\"))\n",
    "score, accuracy = model.evaluate(test_tweets, pd.get_dummies(test_data['Sentiment']).values, batch_size = 128)\n",
    "print(\"Test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
