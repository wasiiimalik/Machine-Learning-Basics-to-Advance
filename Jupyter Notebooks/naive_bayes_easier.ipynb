{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS DATA:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " IRIS TARGET NAMES: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " Dataset Mean\n",
      "         Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\n",
      "Target                                                      \n",
      "0           4.990000     3.452500      1.450000     0.245000\n",
      "1           5.919512     2.770732      4.241463     1.321951\n",
      "2           6.533333     2.966667      5.520513     2.000000\n",
      "\n",
      " Dataset Variance\n",
      "         Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\n",
      "Target                                                      \n",
      "0           0.127077     0.156404      0.033846     0.011256\n",
      "1           0.294110     0.102622      0.231488     0.042256\n",
      "2           0.427544     0.101754      0.293252     0.084211\n",
      "\n",
      " Test Data:\n",
      "      Sepal_Length  Sepal_Width  Petal_Length  Petal_Width  Target\n",
      "73            6.1          2.8           4.7          1.2       1\n",
      "18            5.7          3.8           1.7          0.3       0\n",
      "118           7.7          2.6           6.9          2.3       2\n",
      "78            6.0          2.9           4.5          1.5       1\n",
      "76            6.8          2.8           4.8          1.4       1\n",
      "31            5.4          3.4           1.5          0.4       0\n",
      "64            5.6          2.9           3.6          1.3       1\n",
      "141           6.9          3.1           5.1          2.3       2\n",
      "68            6.2          2.2           4.5          1.5       1\n",
      "82            5.8          2.7           3.9          1.2       1\n",
      "110           6.5          3.2           5.1          2.0       2\n",
      "12            4.8          3.0           1.4          0.1       0\n",
      "36            5.5          3.5           1.3          0.2       0\n",
      "9             4.9          3.1           1.5          0.1       0\n",
      "19            5.1          3.8           1.5          0.3       0\n",
      "56            6.3          3.3           4.7          1.6       1\n",
      "104           6.5          3.0           5.8          2.2       2\n",
      "69            5.6          2.5           3.9          1.1       1\n",
      "55            5.7          2.8           4.5          1.3       1\n",
      "132           6.4          2.8           5.6          2.2       2\n",
      "29            4.7          3.2           1.6          0.2       0\n",
      "127           6.1          3.0           4.9          1.8       2\n",
      "26            5.0          3.4           1.6          0.4       0\n",
      "128           6.4          2.8           5.6          2.1       2\n",
      "131           7.9          3.8           6.4          2.0       2\n",
      "145           6.7          3.0           5.2          2.3       2\n",
      "108           6.7          2.5           5.8          1.8       2\n",
      "143           6.8          3.2           5.9          2.3       2\n",
      "45            4.8          3.0           1.4          0.3       0\n",
      "30            4.8          3.1           1.6          0.2       0\n",
      "\n",
      "Accuracy of the classifier: 0.97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(\"IRIS DATA:\\n\", iris.data)\n",
    "print(\"\\n IRIS TARGET NAMES:\",iris.target_names)\n",
    "X = pd.DataFrame(iris.data)\n",
    "X.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\n",
    "y = pd.DataFrame(iris.target)\n",
    "y.columns = ['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "#--------------------------------------------------------------------------------------retrieve_values\n",
    "n_0 = data['Target'][data['Target'] == 0].count()\n",
    "n_1 = data['Target'][data['Target'] == 1].count()\n",
    "n_2 = data['Target'][data['Target'] == 2].count()\n",
    "total = len(data)\n",
    "\n",
    "#no of 0,1,2 classes divided by the total rows \n",
    "p_0 = n_0 / total    \n",
    "p_1 = n_1 / total   \n",
    "p_2 = n_2 / total\n",
    "\n",
    "# group the data by target & calculate the means of each feature\n",
    "data_means = data.groupby('Target').mean()\n",
    "print('\\n Dataset Mean\\n', data_means)\n",
    "\n",
    "# calculate the data variance \n",
    "# variance = summation of((mean - x) ** 2) / n \n",
    "data_variance = data.groupby('Target').var()\n",
    "print('\\n Dataset Variance\\n', data_variance)\n",
    "\n",
    "#--------------------------------------------------------------------------------------class 0 variables\n",
    "    \n",
    "#mean for class 0 \n",
    "class_0_SL_mean = data_means['Sepal_Length'][data_means.index == 0].values[0]\n",
    "class_0_SW_mean =  data_means['Sepal_Width'][data_means.index == 0].values[0]\n",
    "class_0_PL_mean =  data_means['Petal_Length'][data_means.index == 0].values[0]\n",
    "class_0_PW_mean =  data_means['Petal_Width'][data_means.index == 0].values[0]\n",
    "\n",
    "#variance for class 0 \n",
    "class_0_SL_variance = data_variance['Sepal_Length'][data_variance.index == 0].values[0] \n",
    "class_0_SW_variance = data_variance['Sepal_Width'][data_variance.index == 0].values[0] \n",
    "class_0_PL_variance = data_variance['Petal_Length'][data_variance.index == 0].values[0] \n",
    "class_0_PW_variance = data_variance['Petal_Width'][data_variance.index == 0].values[0] \n",
    "\n",
    "#--------------------------------------------------------------------------------------class 1 variables\n",
    "\n",
    "#mean for class 1 \n",
    "class_1_SL_mean = data_means['Sepal_Length'][data_means.index == 1].values[0]\n",
    "class_1_SW_mean =  data_means['Sepal_Width'][data_means.index == 1].values[0]\n",
    "class_1_PL_mean =  data_means['Petal_Length'][data_means.index == 1].values[0]\n",
    "class_1_PW_mean =  data_means['Petal_Width'][data_means.index == 1].values[0]\n",
    "\n",
    "#variance for class 1 \n",
    "class_1_SL_variance = data_variance['Sepal_Length'][data_variance.index == 1].values[0] \n",
    "class_1_SW_variance = data_variance['Sepal_Width'][data_variance.index == 1].values[0] \n",
    "class_1_PL_variance = data_variance['Petal_Length'][data_variance.index == 1].values[0] \n",
    "class_1_PW_variance = data_variance['Petal_Width'][data_variance.index == 1].values[0] \n",
    "\n",
    "#--------------------------------------------------------------------------------------class 2 variables\n",
    "\n",
    "#mean for class 2 \n",
    "class_2_SL_mean = data_means['Sepal_Length'][data_means.index == 2].values[0]\n",
    "class_2_SW_mean =  data_means['Sepal_Width'][data_means.index == 2].values[0]\n",
    "class_2_PL_mean =  data_means['Petal_Length'][data_means.index == 2].values[0]\n",
    "class_2_PW_mean =  data_means['Petal_Width'][data_means.index == 2].values[0]\n",
    "\n",
    "#variance for class 2 \n",
    "class_2_SL_variance = data_variance['Sepal_Length'][data_variance.index == 2].values[0] \n",
    "class_2_SW_variance = data_variance['Sepal_Width'][data_variance.index == 2].values[0] \n",
    "class_2_PL_variance = data_variance['Petal_Length'][data_variance.index == 2].values[0] \n",
    "class_2_PW_variance = data_variance['Petal_Width'][data_variance.index == 2].values[0] \n",
    "\n",
    "\n",
    "def p_x_given_y(x, mean_y, variance_y):\n",
    "# a function which calculates p(x|y)\n",
    "   \n",
    "    #input the arguments into a probability density function\n",
    "    p = 1/( np.sqrt(2*np.pi*variance_y) )  *  np.exp( (-(x-mean_y) ** 2)/(2*(variance_y **2)))\n",
    "    return p\n",
    "\n",
    "\n",
    "def result(): \n",
    "    test_data=pd.concat([X_test, y_test], axis=1)\n",
    "    pred=[]\n",
    "    print(\"\\n Test Data:\\n\",test_data)\n",
    "    for rowIndex, row in test_data.iterrows():\n",
    "        #print('\\nTest Instance {0}: \\n '. format(rowIndex),row)\n",
    "\n",
    "        prob_0 = p_0 * \\\n",
    "                p_x_given_y(row['Sepal_Length'], class_0_SL_mean, class_0_SL_variance) * \\\n",
    "                p_x_given_y(row['Sepal_Width'], class_0_SW_mean, class_0_SW_variance) * \\\n",
    "                p_x_given_y(row['Petal_Length'], class_0_PL_mean, class_0_PL_variance) * \\\n",
    "                p_x_given_y(row['Petal_Width'], class_0_PW_mean, class_0_PW_variance)\n",
    "        #print('\\nProbability of class 0:', prob_0)\n",
    "\n",
    "        prob_1 = p_1 * \\\n",
    "                p_x_given_y(row['Sepal_Length'], class_1_SL_mean, class_1_SL_variance) * \\\n",
    "                p_x_given_y(row['Sepal_Width'], class_1_SW_mean, class_1_SW_variance) * \\\n",
    "                p_x_given_y(row['Petal_Length'], class_1_PL_mean, class_1_PL_variance) * \\\n",
    "                p_x_given_y(row['Petal_Width'], class_1_PW_mean, class_1_PW_variance)\n",
    "        #print('\\nProbability of class 1:', prob_1)\n",
    "        \n",
    "        prob_2 = p_2 * \\\n",
    "                p_x_given_y(row['Sepal_Length'], class_2_SL_mean, class_2_SL_variance) * \\\n",
    "                p_x_given_y(row['Sepal_Width'], class_2_SW_mean, class_2_SW_variance) * \\\n",
    "                p_x_given_y(row['Petal_Length'], class_2_PL_mean, class_2_PL_variance) * \\\n",
    "                p_x_given_y(row['Petal_Width'], class_2_PW_mean, class_2_PW_variance)\n",
    "        #print('\\nProbability of class 2:', prob_2)\n",
    "        \n",
    "        if (prob_0 >= prob_1) and (prob_0 >= prob_2):\n",
    "            pred.append(0)\n",
    "        elif (prob_1 >= prob_0) and (prob_1 >= prob_2):\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(2)\n",
    "         \n",
    "    print(\"\\nAccuracy of the classifier: {:.2f}\".format(sm.accuracy_score(y_test, pred)))\n",
    "    \n",
    "result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
